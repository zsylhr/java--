## 1.我看你在项目中有用到redis，你们主要使用场景有哪些呢？
在我们的业务中，主要使用redis做缓存和分布式锁。（除此之外，redis还可以用来做计数器、保存token、消息队列以及延时队列）

## 2.我看你有说到使用redis做缓存的场景，那么你知道什么是缓存穿透、击穿、雪崩吗？遇见这些情况怎么解决？
a.缓存穿透指的是：比如我有一个查询请求，查询id为1000对应的数据，在查询的过程中，先对redis缓存进行查询，查询不到之后接着对DB进行查询，依然查询不到，并且这种情况下不会写入缓存，导致之后的每次请求都会查DB，这种情况就叫做缓存穿透。
对于这种情况通常有两种解决办法：
一是在redis中缓存null值，也就是说每次查DB查询不到时，都向redis中写入一个{"id":xxx, "value":null}的键值对，这样之后再查询就会在缓存处直接返回null了，但是这样做会有一些问题，比如我们的网站被攻击时，别人可能会使大量非重复的查询，这样我们的redis中就会写入大量空值，内存压力上升，同时非重复的查询依然会查DB, DB的压力还是很大，而且之后如果这些key如果在数据库中有值了，也有可能会导致数据不一致的问题。
在我们的项目中采用的是另一种方法，在查询redis缓存之前添加一个布隆过滤器，布隆过滤器本质上是一个bitmap(位图),或者说是一个位数组，当一个元素被添加进来时，我们通过K个不同的hash函数将这个元素映射为K个不同的hash值，之后将数组中索引为这些hash的设置为1，之后进行查询时只需判断查询元素在数组对应的K个值是否全部为1就行了，从而实现过滤的效果。不过由于hash碰撞的原因，使用布隆过滤器不能百分百过滤数据库中不存在的元素，会有一定的误差率（数组越大误差越小，但是数组带来的内存消耗会变大），不过这个误差率通过设置数组的长度是可以进行控制的。在我们的项目中，设置的误差率是5%，我们觉得这个程度的异常流量访问到DB是可以接受的。

b.缓存击穿指的是给某个key设置了过期时间，然后当这个key过期的时候，同一时间有对这个key有大量并发请求，（在key重新写入redis的几十毫秒内）这些并发请求会访问到DB上，从而大幅增加DB压力，甚至把DB打垮。
这种情况也有两种解决方法：
在我们的业务中，对数据的强一致性要求比较高，使用的是互斥锁的方法。对于刚刚描述的大量请求，当线程1查询缓存未命中时，会去获取互斥锁，获取互斥锁成功后，接着查询DB, 写入缓存，最后释放互斥锁。线程2查询缓存未命中时，也会去获取互斥锁，但此时锁已经被线程1占有，线程2获取互斥锁失败，接着它就会休眠一会儿，然后继续查询缓存，然后获取互斥锁，一直重复这个过程，直至线程1写入缓存之后，线程2查询缓存成功，返回缓存数据。使用互斥锁的好处就是数据的强一致性，但是性能会差一些。
如果对性能要求比较高，对一致性的要求比较低，可以采用逻辑过期的方法。也就是说不给redi中的key设置过期时间，而是在写入redis时，在数据中新增一个过期时间字段，之后通过这个字段来判断是否过期。当线程1查询缓存时，通过这个字段判断已经过期，然后就会去获取一个互斥锁，接着会开启一个线程2，线程2会查询数据库，写入redis，重设过期时间并释放互斥锁，线程1在开启线程2之后，会直接返回redis的过期数据，不会等待线程2的执行完成。同时，当线程3查询缓存时，发现已经过期，并且获取互斥锁也失败，那么会直接返回缓存中的过期数据。这种方法没有等待互斥锁的过程，因此性能比较好，但是会返回过期数据，只能保证高可用性。

c.缓存雪崩指的是设置缓存时设计了相同的过期时间，导致同一时间有大量缓存失效，请求全部转发给了DB,DB压力瞬间增大导致雪崩。此外Redis服务宕机也会导致雪崩
对于同一时间大量缓存失效，我们可以对不同的key设置随机的TTL,让它们的过期时间充满随机性。对于Redis服务宕机，可以提高redis服务的可用性，比如哨兵模式和集群模式。此外还可以采用降级限流的方式，通过配置nginx或者springcloud gateway来实现。此外还可以给我们的业务设置多级缓存

## 3.你们mysql和redis的数据是怎么进行同步的？（双写一致性）

在我们的业务中，物料的信息是一个比较底层的数据，通常在添加之后很少进行修改，大部分的操作都是查询，而且这个数据与别的业务交互比较多，要求实时准确性，因此我们采用了读写锁来保证数据的一致性问题。我们使用的是redission实现的读写锁。在对数据进行读操作时，会添加一个共享锁，也就是读锁readLock，这个锁可以保证读读不互斥、读写互斥，也就是别的线程同一时间只能读不能写。在对数据进行写操作时，会添加一个排他锁，也就是写锁writeLock，它是读写，写写都互斥的，在进行写操作时，别的线程同一时间不能进行读写操作，避免了脏数据的产生。此外，我们的数据之间是独立的，对同一数据进行的读写操作使用的是同一把锁。

在我们别的业务中，也有一些允许延时一致的场景，比如说出入库的一些单据，这些单据通常在执行之后很久用户才会进行查看，对于这种情况，我们采用的是异步的方案，也就是在对DB进行写操作后，通过MQ发送消息，通知redis缓存进行更新，保证数据的最终一致性。除此之外异步方案还可以采用canal监听数据库binlog的方式来实现

### 3.1 了解延时双删吗？为什么不采用延时双删的策略？
有一定了解。因为采用延时双删后，在写操作的时候会出现问题，通常我们先删除缓存中的数据，然后更新数据库中的数据，最后延时删除缓存中的数据，在这个过程中，别的线程读取的数据库中的旧数据不知道什么时候会写入缓存，这个时间不好把控，延时的时间是不好确定的，这样就有产生脏数据的风险，并且不能保证强一致性，因此我们没有采用这个策略

## 4.redis做缓存的时候，数据的持久化是怎么做的？
Redis的持久化分为两种，RDB以及AOF。
RDB(Redis Database Backup file)，也就是Redis数据备份文件。简单来说，就是对内存中的数据进行一个快照，存储在磁盘上。当Redis服务宕机重启后，从该磁盘读取数据文件来恢复数据。
AOF(Append Only File)，也就是追加文件，会把redis的每一次写操作都记录在AOF文件中，当redis服务宕机重启时，会从AOF文件中读取操作命令重新执行一遍。
### 4.1 哪种方式恢复数据更快？
RDB文件是二进制文件，而且保存的时候体积比较小，使用它来进行数据恢复比较快，但是它可能会丢失一些数据。对于数据安全性要求比较高的场景，我们通常会使用AOF的方式，虽然AOF恢复数据较慢，但是它丢失数据的风险比较低，在我们的项目中采用的是每秒进行一次的刷盘策略，也就是说，最多只会丢失一秒的数据。
#### 4.1.1 按照你的说法，仍然可能会丢失一秒的数据，导致数据不一致的问题，你们是如何解决的？
AOF除了可以设置每秒进行一次刷盘外，也可以设置为实时同步，但是这种刷盘策略对设备的性能占有比较高，因此我们没有采用。我们是对这种情况做了一个补偿策略，因为数据库中的数据是有更新时间的，我们只需要根据更新时间，把丢失的数据重新进行同步就行

## 5.redis中的key过期后，你们是怎么删除的？（删除策略）
我们同时采用了两种删除策略，一种是惰性删除，也就是redis的key过期后，只有对过期的key进行访问时，才会删除该key；另一种是定期删除策略，也就是定期检查redis中一定量的key是否过期，如果过期就删除，对于定期删除策略，采用的是它的slow模式，因为它的频率固定并且可以在conf文件中设置它的频率

## 6.如果缓存太多，而你们的内存有限，内存满了该怎么办？（数据淘汰策略）
redis支持8种数据淘汰策略，我们采用的是最近最少使用策略，也就是allkeys-lru策略，这样的话，redis中留下的会是热点数据。（其余的策略还有noeviction, 满的时候不淘汰任何key值，不允许写入新数据；volatile-ttl,对设置了ttl的key,比较剩余ttl时间，时间短的淘汰；allkeys-random: 在所有key中随机淘汰；volatile-ttl:在设置了ttl的key中随机淘汰；volatile-lru; allkeys-lfu; volatile-lfu, lfu策略会统计key的访问频率，频率低的淘汰）

## 7.你们redis做分布式锁主要用在哪个场景中？是怎么实现的？
在我们的业务中有一个库存的概念，对于库存数量的变更用到了redis的分布式锁，并且采用的是redission实现的分布式锁，它的底层是setnx以及用来保证原子性的lua脚本

### 7.1 Redission中是怎么合理控制锁的时长的？
在redission的分布式锁中，提供了一个WatchDog(看门狗)，当一个线程获取锁成功后，WathcDog会给持有锁的线程续期（续期时长时 释放时间/3， 默认是10秒）

### 7.2 Redission的锁可重入吗？
是可以重入的，当多个锁重入时会判断是否是获取了锁的线程。redis中使用了一个hash结构用来存储锁的线程信息以及重入的次数，当多个锁重入时，会通过存储的信息来进行一个判断

### 7.3 Redissiond锁能解决主从一致的问题吗？
不可以，但是Redission中提供了一个红锁可以解决主从一致的问题。红锁指的是在超过一半的Redis节点中创建锁的信息，但是这样性能会很差。如果非要保证主从一致的话，可以采用zookeeper实现的分布式锁。

# 8.Redis的有哪些集群方案？
一共有三种集群方案：主从复制（主从同步），哨兵模式，分片集群

## 8.1 介绍一下主从复制以及主从同步数据的流程
对于Redis来说，单节点的并发能力是有上限的，如果要进一步提高Redis的并发能力，可以搭建Redis主从集群，从而实现Redis的读写分离。一般来说，会有一个主节点和多个从节点，主节点负责写数据，从节点负责读数据。而主节点写入数据之后，需要把数据同步到从节点。
对于主从同步数据的流程，分为全量同步以及增量同步。在从节点第一次与主节点建立连接时会使用全量同步，主要流程是这样的：1.首先从节点向主节点发送数据同步的请求，并附带上自己的replication id和offset；2.然后主节点根据replication id判断是否是第一次同步数据，如果这个从节点发送的replication id与主节点不一致，那么就是第一次数据同步；3.这个时候主节点会将自己的replication id和offset发给从节点，使主从保持一致；4.接着主节点会执行bgsave命令，生成一个rdb文件，并发给从节点执行，从节点收到rdb文件后会清除自己的数据并执行rdb文件来实现数据同步；5.在rdb文件的生成执行期间，如果有新的写操作发送到了主节点，那么主节点会以命令的方式将它们记载到缓冲区的日志文件，最后把这个日志文件发送给从节点，从而保证主节点和从节点的数据完全一致。而这个日志文件，则是我们后续增量同步的一个依赖，对于增量同步，1.从节点仍然会发送同步数据的请求，然后主节点判断replication id一致，说明这次不是第一次请求；2.那么主节点会接着比较主从节点的offset, 比如从节点offset是100，主节点offset是200，那么主节点就会在刚刚所说的日志文件中获取从节点offset之后的数据，并将其发送给从节点进行同步。

## 8.2 介绍一下哨兵模式
哨兵模式指的是实现Redis主从集群自动故障恢复的一致模式，有着监控、自动故障恢复，以及通知的功能
### 8.2.1 Redis集群的脑裂是什么？如何解决？
在我们使用Redis哨兵模式的时候，如果我们的主节点、从节点、哨兵(sentinel)处于不同的网络分区，这个时候由于网络原因导致哨兵没有感知到主节点，那么它就会在从节点中选举一个新的主节点，这时候就有了两个主节点，就像大脑分裂一样，所以称为脑裂。这样会导致客户端还在老的主节点进行写数据，当网络恢复正常的时候，哨兵将老的主节点降级为从节点，这时候会从新的主节点同步数据，从而导致大量数据的丢失。
关于解决方案，我们可以在redis的配置文件conf中进行配置，比如可以合理设置从节点的最小数量以及降低主从节点同步数据的延迟时间，当达不到配置的这两个要求时，就拒绝来自客户端的请求，从而减少数据的丢失数量，避免大量数据丢失（不能完全防止数据丢失，并且脑裂没法彻底解决，因为在Redis的集群内部没有共识算法来维护多个节点的强一致性，它不像zookeeper那样，必须成功写入大多数节点才算写入成功）

## 8.3 介绍一下分片集群
分片集群指的是在我们的Redis集群中有多个主节点，每个主节点保存不同的数据，同时每个主节点有多个从节点，主节点之间还会通过互相ping来监测彼此的健康状态，此外客户端的请求还可以访问集群的任意节点，并且这个请求会通过路由策略最终被转发到正确的节点。
### 8.3.1 分片集群中的数据是怎么存储和读取的？
在分片集群中引入了一个哈希槽的概念，Redis集群一共有2的14次方个哈希槽，并通过一定的策略对实例进行分配，当对数据进行读写时，会计算key值的hash值，如果key前面有大括号，那么计算的是大括号中的内容的hash值，然后将hash值对2的14次方进行取余，这个余数就是对应的hash槽号，然后根据hash槽号来寻找对应的Redis节点

## 8.4 你们的Redis集群是什么样的？
我们的redis采用的主从+哨兵的模式。主从数量都是1，单节点不超过10G内存。因为Redis单节点的并发已经很高，写操作能达到8w的并发，读操作能达到10w的并发。当内存不够时，比如一些热点数据比较大的业务，我们会给不同的业务服务分配独立的主从节点，比如我们的物料用一套主从节点，库存用一套主从节点

## 9. Redis是单线程还是多线程，为什么那么快？
redis是单线程的，它非常快的原因主要有3个，1.redis是完全基于内存的，不会受到磁盘IO的限制；2.redis采用单线程操作，避免了不必要的上下文切换和竞争条件；3.redis采用了非阻塞IO多路复用机制。不过在redis6.0之后，为了提升redis的性能，引用了多线程IO，用于加快处理网络数据的读写以及协议的解析，执行命令使用的仍然是单线程

### 9.1 什么是非阻塞IO多路复用？
这里我先介绍一下什么是阻塞IO和非阻塞IO，阻塞IO指的是用户应用向内核请求数据，如果内核没有数据，那么就阻塞到有数据，接着继续等待内核将数据拷贝到用户空间，直到拷贝完成，用户应用才能处理数据，整个过程都是一个阻塞的状态。
对于非阻塞IO,用户应用向内核请求数据后，如果内核没有数据，那么会直接向用户应用返回一个错误码或者提示没有数据，这时用户可以隔一段时间再发起请求，直到内核有数据了，再继续等待内核将数据拷贝到用户空间，并在之后进行数据处理，也就是说，在等待内核数据的过程中，如果没有数据，用户会直接得到没有数据的结果，这时候用户可以去进行别的动作。
而对于非阻塞IO多路复用，指的是利用单个线程来监听多个FD，也就是文件描述符，Socket也是FD的一种，当某个FD可读或者可写时，这个线程会得到通知，从而避免无效的等待，充分利用CPU的资源。目前的IO多路复用通常都是采用epoll的模式实现，而不是select和poll,对于epoll模式，它会通知用户Socket就绪的同时，把已就绪的Socket写入用户空间，不需要再依次遍历Socket来判断是否就绪，提高了性能。(epoll机制：通过一个红黑树记录需要监听的FD, 通过一个链表记录已经就绪的FD, 在FD添加进红黑树时，会添加一个callback函数，当该FD进行读写等操作时，会触发这个callback函数，从而将FD的引用放到链表中，之后就可以通过这个链表判断哪些FD已就绪)